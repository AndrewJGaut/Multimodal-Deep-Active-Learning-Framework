{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.10.0\n",
      "Torchvision Version:  0.11.1\n"
     ]
    }
   ],
   "source": [
    "# Adapted from https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "# for kaggle satellite image classification dataset https://www.kaggle.com/mahmoudreda55/satellite-image-classification\n",
    "# and then basic active learning was applied.\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_finetuning_utils import train_model, train_model_given_numpy_arrays, initialize_model\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from test_framework.model_interface import ModelInterface\n",
    "from test_framework.tester import Tester\n",
    "from utils.data_utils import get_kaggle_satellite_image_classification_dataset_as_numpy_arrays\n",
    "import categorical_query_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"../data/kaggle_satellite_image_classification\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"squeezenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 4\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 3#15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "# Use ~1/10 of the dataset\n",
    "small_dataset = True\n",
    "\n",
    "# parameters specific to active learning\n",
    "active_learning_batch_size = 8\n",
    "initial_train_data_fraction = 0.50\n",
    "QUERY_FUNCTION = categorical_query_functions.MIN_MAX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data,y_data = get_kaggle_satellite_image_classification_dataset_as_numpy_arrays()\n",
    "order = np.random.permutation(len(x_data))\n",
    "x_data, y_data = x_data[order], y_data[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearningModel(ModelInterface):\n",
    "    def __init__(self,model,name=\"no name provided\",details=\"no details provided\"):\n",
    "        model.to(device)\n",
    "        self.model = model\n",
    "        self._name = name\n",
    "        self._details = details\n",
    "        # Gather the parameters to be optimized/updated in this run. If we are\n",
    "        #  finetuning we will be updating all parameters. However, if we are\n",
    "        #  doing feature extract method, we will only update the parameters\n",
    "        #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "        #  is True.\n",
    "        params_to_update = model.parameters()\n",
    "        verbose = False\n",
    "        if verbose:\n",
    "            print(\"Params to learn:\")\n",
    "        if feature_extract:\n",
    "            params_to_update = []\n",
    "            for name,param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    params_to_update.append(param)\n",
    "                    if verbose:\n",
    "                        print(\"\\t\",name)\n",
    "        elif verbose:\n",
    "            for name,param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(\"\\t\",name)\n",
    "\n",
    "        # Observe that all parameters are being optimized\n",
    "        optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "        self._optimizer = optimizer_ft\n",
    "        \n",
    "        # store criterion\n",
    "        self._criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def name(self) -> str:\n",
    "        return self._name\n",
    "    def details(self) -> str:\n",
    "        return self._details\n",
    "    def train(self, train_x:np.ndarray, train_y:np.ndarray) -> None:\n",
    "        self.model = train_model_given_numpy_arrays(self.model, train_x, train_y, self._criterion, self._optimizer, num_epochs, batch_size, verbose=False)\n",
    "    def predict(self, test_x:np.ndarray):\n",
    "        x_tensor = torch.tensor(test_x)\n",
    "        dataset = TensorDataset(x_tensor)\n",
    "        dataloader = DataLoader(dataset,batch_size=batch_size,num_workers=0,shuffle=True)\n",
    "        preds_list = []\n",
    "        for (inputs,) in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            preds_list.append(self.model(inputs).cpu().detach().numpy())\n",
    "        return np.vstack(preds_list)\n",
    "    def query(self, unlabeled_data:np.ndarray, labeling_batch_size:int) -> np.ndarray:\n",
    "        self.model.eval()\n",
    "        softmax = lambda x: np.exp(x)/np.sum(np.exp(x),axis=-1,keepdims=True)\n",
    "        softmax_outputs = softmax(self.predict(unlabeled_data))\n",
    "        indices = QUERY_FUNCTION(softmax_outputs,labeling_batch_size)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_onehot = np.zeros((y_data.size, y_data.max()+1))\n",
    "y_data_onehot[np.arange(y_data.size),y_data] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if small_dataset:\n",
    "    tester = Tester(x_data[:600],y_data_onehot[:600])\n",
    "else:\n",
    "    tester = Tester(x_data,y_data_onehot)\n",
    "tester.TRAINING_EPOCHS = num_epochs\n",
    "tester.ACTIVE_LEARNING_BATCH_SIZE = active_learning_batch_size\n",
    "tester.INITIAL_TRAIN_DATA_FRACTION = initial_train_data_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning_model = ActiveLearningModel(model_ft,model_name,str(model_ft.classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.test_model(active_learning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([mr.training_performance for mr in tester.model_results])\n",
    "print([mr.test_performance for mr in tester.model_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "572989d3e5e970065861bb6fc65bf74562091858dbe06814b9896f38cf561588"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cs229proj': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
